# LLM × Game Theory

## Legend
- <span style="color:#1E90FF;">**Evaluate**</span> — Evaluate the performance of LLMs in game-theoretic tasks.  
- <span style="color:#FF8C00;">**Enhance: LLM for Game**</span> — Improve LLMs to perform better in game-theoretic tasks.  
- <span style="color:#FF4500;">**Enhance: Game for LLM**</span> — Use game-theoretic tasks to improve the general capabilities of LLMs.  

---

## Survey

### 2025

1. **[From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium](https://arxiv.org/abs/2506.08292)** — <span style="color:#FF8C00;">*Enhance: LLM for Game*</span> [code](https://github.com/tmlr-group/ECON)  
   *Xie Yi, Zhanke Zhou, Chentao Cao, Qiyu Niu, Tongliang Liu, Bo Han.* ICML '25.

2. **[Competing Large Language Models in Multi-Agent Gaming Environments (GAMABench)](https://openreview.net/forum?id=DI4gW8viB6)** — <span style="color:#1E90FF;">*Evaluate*</span> [code](https://github.com/CUHK-ARISE/GAMABench)  
   *Jen-tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang, Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Michael Lyu.* ICLR '25.

3. **[Can LLMs Effectively Provide Game-Theoretic-Based Scenarios for Cybersecurity?](https://arxiv.org/abs/2508.05670)** — <span style="color:#FF4500;">*Enhance: Game for LLM*</span>  
   *Daniele Proverbio, Alessio Buscemi, Alessandro Di Stefano, The Anh Han, German Castignani, Pietro Liò.* Preprint '25.

4. **[Playing Repeated Games with Large Language Models](https://www.nature.com/articles/s41562-025-02172-y)** — <span style="color:#1E90FF;">*Evaluate*</span>  
   *Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, Eric Schulz.* Nature Human Behaviour '25.

5. **[Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats](https://arxiv.org/abs/2507.10621)** — <span style="color:#FF4500;">*Enhance: Game for LLM*</span>  
   *Quanyan Zhu.* Preprint '25.

---

### 2024

1. **[GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations](https://proceedings.neurips.cc/paper_files/paper/2024/file/3191170938b6102e5c203b036b7c16dd-Paper-Conference.pdf)** — <span style="color:#1E90FF;">*Evaluate*</span> [code](https://github.com/jinhaoduan/GTBench)  
   *Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, Kaidi Xu.* NeurIPS '24.

2. **[Game-theoretic LLM: Agent Workflow for Negotiation Games](https://arxiv.org/abs/2411.05990)** — <span style="color:#FF4500;">*Enhance: Game for LLM*</span>  
   *Wenyue Hua, Ollie Liu, Lingyao Li, Alfonso Amayuelas, Julie Chen, Lucas Jiang, Mingyu Jin, Lizhou Fan, Fei Sun, William Wang, Xintong Wang, Yongfeng Zhang.* Preprint '24.

3. **[Strategic Behavior of Large Language Models and the Role of Game Structure versus Contextual Framing](https://www.nature.com/articles/s41598-024-69032-z)** — <span style="color:#1E90FF;">*Evaluate*</span>  
   *Nunzio Lorè, Babak Heydari.* Scientific Reports '24.

4. **[Language Games, Game Theory, and Large Language Models: A Mathematical Framework](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4963848)** — <span style="color:#FF8C00;">*Enhance: LLM for Game*</span>  
   *Miquel Noguer I Alonso.* SSRN '24.

5. **[Autoformalizing and Simulating Game-Theoretic Scenarios using LLM-augmented Agents](https://pure.royalholloway.ac.uk/files/65087740/2412.08805v1.pdf)** — <span style="color:#1E90FF;">*Evaluate*</span>  
   *Agnieszka Mensfelt, Kostas Stathis, Vince Trencsenyi.* Preprint '24.

---

### 2023

1. **[ALYMPICS: LLM Agents Meet Game Theory](https://arxiv.org/abs/2311.03220)** — <span style="color:#1E90FF;">*Evaluate*</span> [code](https://github.com/microsoft/Alympics)  
   *Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu, Xun Wang, Fengyi Wang, Tao Ge, Furu Wei.* Preprint '23.

2. **[Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis](https://arxiv.org/abs/2308.06180)** — <span style="color:#1E90FF;">*Evaluate*</span>  
   *Fan Lu, Weihao Guo, Yiqi Li, Xinyu Wang, Tianyu Yu.* Preprint '23.
